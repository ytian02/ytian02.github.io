<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta name=generator content="Hugo 0.154.5"><meta name=theme content='FixIt v0.4.2-20260109063229-50d27e0e'><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Kanat Space</title><meta name=author content="ty"><meta name=description content><meta name=keywords content='程序员'><meta itemprop=name content="Kanat Space"><meta itemprop=datePublished content="2026-01-18T20:22:17+08:00"><meta itemprop=dateModified content="2026-01-18T20:22:17+08:00"><meta itemprop=image content="https://ytian02.github.io/logo.png"><meta property="og:url" content="https://ytian02.github.io/"><meta property="og:site_name" content="Kanat Space"><meta property="og:title" content="Kanat Space"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="website"><meta property="og:image" content="https://ytian02.github.io/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ytian02.github.io/logo.png"><meta name=twitter:title content="Kanat Space"><meta name=application-name content="Kanat Space"><meta name=apple-mobile-web-app-title content="Kanat Space"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical type=text/html href=https://ytian02.github.io/ title="Kanat Space"><link rel=alternate type=application/rss+xml href=https://ytian02.github.io/index.xml title="Kanat Space"><link rel=alternate type=application/json href=https://ytian02.github.io/index.json title="Kanat Space"><link rel=alternate type=text/plain href=https://ytian02.github.io/baidu_urls.txt title="Kanat Space"><link rel=stylesheet href=/css/config.min.edcf12a20c095857f60c14e145d8be29ece19cc0db3d2920f3a5d91af1bf37dd.css integrity="sha256-7c8SogwJWFf2DBThRdi+KezhnMDbPSkg86XZGvG/N90="><link rel=stylesheet href=/css/style.min.cd50422fdba3ab99b27445151d5da66b7069a6d4b2b37a399bb8141f865a718f.css integrity="sha256-zVBCL9ujq5mydEUVHV2ma3BpptSys3o5m7gUH4ZacY8="><link rel=preload href=/lib/fontawesome-free/all.min.320d572dfb844e7152480b7b62374236c4896ccca3ac9d69bb03f3bc2034acb8.css integrity="sha256-Mg1XLfuETnFSSAt7YjdCNsSJbMyjrJ1puwPzvCA0rLg=" as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.320d572dfb844e7152480b7b62374236c4896ccca3ac9d69bb03f3bc2034acb8.css integrity="sha256-Mg1XLfuETnFSSAt7YjdCNsSJbMyjrJ1puwPzvCA0rLg="></noscript><link rel=preload href=/lib/animate/animate.min.5fbaeb9f8e25d7e0143bae61d4b1802c16ce7390b96ceb2d498b0d96ff4c853f.css integrity="sha256-X7rrn44l1+AUO65h1LGALBbOc5C5bOstSYsNlv9MhT8=" as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.5fbaeb9f8e25d7e0143bae61d4b1802c16ce7390b96ceb2d498b0d96ff4c853f.css integrity="sha256-X7rrn44l1+AUO65h1LGALBbOc5C5bOstSYsNlv9MhT8="></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","url":"https:\/\/ytian02.github.io\/","inLanguage":"zh-CN","author":{"@type":"Person","name":"ty"},"image":"https:\/\/ytian02.github.io\/favicon.ico","thumbnailUrl":"https:\/\/ytian02.github.io\/favicon-32x32.png","name":"Kanat Space"}</script><script src=/js/head/color-scheme.min.69f5cf37e9eb7ae9de2a537ee9a73161155340dc71103ddd157f324edef64758.js integrity="sha256-afXPN+nreuneKlN+6acxYRVTQNxxED3dFX8yTt72R1g="></script></head><body data-instant-intensity=viewport data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Kanat Space"><img class=logo src=/logo.png alt="Kanat Space" height=32 width=32><span class=header-title-text>Kanat Space</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" role=button aria-label=切换主题 title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Kanat Space"><img class=logo src=/logo.png alt="Kanat Space" height=26 width=26><span class=header-title-text>Kanat Space</span></a><span class=header-subtitle></span></div><div class=theme-switch role=button aria-label=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></div><div class=menu-toggle id=menu-toggle-mobile role=button aria-labelledby=menu-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class="menu-item menu-system"></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=fi-container><div class="page home posts"><div class=home-profile><div class=home-avatar><a href=/posts/ title=文章><img src=/avatar.png alt="Home avatar" height=96 width=96></a></div><h1 class=home-title>Kanat Space</h1><p class=home-subtitle><span class=d-none>Everyone is mania in general</span><span class=typeit><template>Everyone is mania in general</template></span></p><div class=links><a href=https://github.com/https://github.com/ytian02 title=GitHub target=_blank rel="external nofollow noopener noreferrer me"><i class="fa-brands fa-github-alt fa-fw" aria-hidden=true></i>
</a><a href=tel:18156309590 title=Phone target=_blank rel="external nofollow noopener noreferrer me"><i class="fa-solid fa-phone fa-fw" aria-hidden=true></i>
</a><a href=mailto:ytian02@outlook.com title=Email target=_blank rel="external nofollow noopener noreferrer me"><i class="fa-regular fa-envelope fa-fw" aria-hidden=true></i>
</a><a href=/index.xml title=RSS target=_blank rel="external nofollow noopener noreferrer me"><i class="fa-solid fa-rss fa-fw" aria-hidden=true></i></a></div></div><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><span title=置顶 class=icon-pin><i class="fa-solid fa-thumbtack fa-fw" aria-hidden=true></i></span><a href=/posts/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/>写在前面</a></h2><div class=post-meta><span class=post-author><a href=https://github.com/ytian02 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class=avatar src='https://cn.gravatar.com/avatar/609ef319f4ff4685fcbfd26ae99e9d59?s=32&d=identicon' alt=ty height=16 width=16>&nbsp;ty</a></span>&nbsp;<span class=post-publish title='2026-01-18 17:09:57'>发布于 <time datetime=2026-01-18>2026-01-18</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/algorithms/ class=post-category title="分类 - Algorithms"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Algorithms</a> 和 <a href=/collections/reinforcement-learning/ class=post-collection title="合集 - Reinforcement Learning"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Reinforcement Learning</a></span></div><div class=content><ul><li>整理这些内容的初衷是在实习面试前过一遍强化学习，大概花了几天的时间梳理了传统RL的算法，发现很多地方理解不够深刻，所以也对之前一些模棱两可的理解进一步查阅了资料。</li><li>我的强化学习是通过王树森老师的<a href=https://youtu.be/vmkRMvhCW5c target=_blank rel="external nofollow noopener noreferrer">深度强化学习</a>在线课程学习的,其实没有系统性地阅读各个算法的原文,王老师的课程风格简约、深入浅出,很适合初学者。不过在线课程能展示的内容有限，很多细节还是需要通过阅读文字资料才能进一步掌握。</li><li>I-III的内容基本来自于王树森老师的<a href=https://github.com/wangshusen/DRL/tree/master/Notes_CN target=_blank rel="external nofollow noopener noreferrer">《深度强化学习》</a>和上交张伟楠老师、俞勇老师合著的<a href=https://hrl.boyuai.com/ target=_blank rel="external nofollow noopener noreferrer">《动手学强化学习》</a>，IV及之后的内容整理了我知识范围内能接触到的比较有影响力的RL算法。</li><li>整体内容偏知识回顾和总结，不强调算法细节。</li></ul></div><div class=post-footer><a href=/posts/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><span title=置顶 class=icon-pin><i class="fa-solid fa-thumbtack fa-fw" aria-hidden=true></i></span><a href=/posts/i-preliminaries/>I Preliminaries</a></h2><div class=post-meta><span class=post-author><a href=https://github.com/ytian02 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class=avatar src='https://cn.gravatar.com/avatar/609ef319f4ff4685fcbfd26ae99e9d59?s=32&d=identicon' alt=ty height=16 width=16>&nbsp;ty</a></span>&nbsp;<span class=post-publish title='2026-01-10 17:09:18'>发布于 <time datetime=2026-01-10>2026-01-10</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/basic-knowledge/ class=post-category title="分类 - Basic Knowledge"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Basic Knowledge</a> 和 <a href=/collections/reinforcement-learning/ class=post-collection title="合集 - Reinforcement Learning"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Reinforcement Learning</a></span></div><div class=content><h3 class=heading-element id=基本概念><span>基本概念</span>
<a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 class=heading-element id=折扣回报-discounted-return><span>折扣回报 (discounted return)</span>
<a href=#%e6%8a%98%e6%89%a3%e5%9b%9e%e6%8a%a5-discounted-return class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>定义为从当前时刻的状态开始到终止状态结束时所有奖励的之和，考虑到未来奖励的不确定性，引入了折扣因子<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span></span></span></span></p></div><div class=post-footer><a href=/posts/i-preliminaries/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><span title=置顶 class=icon-pin><i class="fa-solid fa-thumbtack fa-fw" aria-hidden=true></i></span><a href=/posts/ii-value-based-rl/>II Value Based RL</a></h2><div class=post-meta><span class=post-author><a href=https://github.com/ytian02 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class=avatar src='https://cn.gravatar.com/avatar/609ef319f4ff4685fcbfd26ae99e9d59?s=32&d=identicon' alt=ty height=16 width=16>&nbsp;ty</a></span>&nbsp;<span class=post-publish title='2026-01-10 19:36:47'>发布于 <time datetime=2026-01-10>2026-01-10</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/algorithms/ class=post-category title="分类 - Algorithms"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Algorithms</a> 和 <a href=/collections/reinforcement-learning/ class=post-collection title="合集 - Reinforcement Learning"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Reinforcement Learning</a></span></div><div class=content><h3 class=heading-element id=基本概念><span>基本概念</span>
<a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>价值学习方法关注如何近似最优价值函数<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q^\ast(s,a)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord><span class="mord mathnormal">Q</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.6887em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal">a</span><span class=mclose>)</span></span></span></span>，使用<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>a</mi></munder><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(a\vert s)=\arg\max\limits_{a}Q^\ast(s,a)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.03588em>π</span><span class=mopen>(</span><span class="mord mathnormal">a</span><span class=mord>∣</span><span class="mord mathnormal">s</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1.45em;vertical-align:-.7em></span><span class=mop>ar<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.4306em><span style=top:-2.4em;margin-left:0><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span><span class=mop>max</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.7em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal">Q</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.6887em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal">a</span><span class=mclose>)</span></span></span></span>作为最优策略。</p></div><div class=post-footer><a href=/posts/ii-value-based-rl/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><span title=置顶 class=icon-pin><i class="fa-solid fa-thumbtack fa-fw" aria-hidden=true></i></span><a href=/posts/iii-policy-based-rl/>III Policy Based RL</a></h2><div class=post-meta><span class=post-author><a href=https://github.com/ytian02 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class=avatar src='https://cn.gravatar.com/avatar/609ef319f4ff4685fcbfd26ae99e9d59?s=32&d=identicon' alt=ty height=16 width=16>&nbsp;ty</a></span>&nbsp;<span class=post-publish title='2026-01-15 21:25:46'>发布于 <time datetime=2026-01-15>2026-01-15</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/algorithms/ class=post-category title="分类 - Algorithms"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Algorithms</a> 和 <a href=/collections/reinforcement-learning/ class=post-collection title="合集 - Reinforcement Learning"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Reinforcement Learning</a></span></div><div class=content><h3 class=heading-element id=基本概念><span>基本概念</span>
<a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>策略学习方法关注如何近似最优策略，优化目标是<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>S</mi></msub><mrow><mo fence="true">[</mo><msup><mi>V</mi><mi>π</mi></msup><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">J(\theta)=\mathbb{E}_S\left[V^\pi(S)\right]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.09618em>J</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.02778em>θ</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord><span class="mord mathbb">E</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05764em>S</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>[</span><span class=mord><span class="mord mathnormal" style=margin-right:.22222em>V</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.6644em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.03588em>π</span></span></span></span></span></span></span></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.05764em>S</span><span class=mclose>)</span><span class="mclose delimcenter" style=top:0>]</span></span></span></span></span>，其中<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6944em></span><span class="mord mathnormal" style=margin-right:.02778em>θ</span></span></span></span>是策略<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.03588em>π</span></span></span></span>的参数。</p></div><div class=post-footer><a href=/posts/iii-policy-based-rl/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><span title=置顶 class=icon-pin><i class="fa-solid fa-thumbtack fa-fw" aria-hidden=true></i></span><a href=/posts/iv-offline-rl/>IV Offline RL</a></h2><div class=post-meta><span class=post-author><a href=https://github.com/ytian02 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class=avatar src='https://cn.gravatar.com/avatar/609ef319f4ff4685fcbfd26ae99e9d59?s=32&d=identicon' alt=ty height=16 width=16>&nbsp;ty</a></span>&nbsp;<span class=post-publish title='2026-01-18 20:22:17'>发布于 <time datetime=2026-01-18>2026-01-18</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/algorithms/ class=post-category title="分类 - Algorithms"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Algorithms</a> 和 <a href=/collections/reinforcement-learning/ class=post-collection title="合集 - Reinforcement Learning"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Reinforcement Learning</a></span></div><div class=content><h3 class=heading-element id=基本概念><span>基本概念</span>
<a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>区别于在线(同策略)强化学习和异策略强化学习方法，离线强化学习从离线的经验回放数组中直接学习一个策略用于和环境交互。
<a href=https://arxiv.org/abs/2005.01643 target=_blank rel="external nofollow noopener noreferrer">&ldquo;Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems&rdquo; (Levine et al., 2023)</a></p></div><div class=post-footer><a href=/posts/iv-offline-rl/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></div></div></article></div></main></div><div class=widgets><div class=fixed-buttons><div class="fixed-button back-to-top animate__faster d-none" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><svg viewBox="0 0 100 100"><circle class="bg" cx="50" cy="50" r="50"/><circle class="progress" cx="50" cy="50" r="50"/></svg></div><div class="fixed-button view-comments d-none" role=button aria-label=查看评论><i class="fa-solid fa-comment fa-fw" aria-hidden=true></i></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/lightgallery/css/lightgallery-bundle.min.120f067ebd6f322339e2ccccd7e87e334d7c7ea5b2bd553f325f2ae3c3ae6fe8.css integrity="sha256-Eg8Gfr1vMiM54szM1+h+M018fqWyvVU/Ml8q48Oub+g="><link rel=preload href=/lib/katex/katex.min.19095127357ed6d29fe0a63a6b000c913a89f7f1963b765dd3715e97c9852e75.css integrity="sha256-GQlRJzV+1tKf4KY6awAMkTqJ9/GWO3Zd03Fel8mFLnU=" as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.19095127357ed6d29fe0a63a6b000c913a89f7f1963b765dd3715e97c9852e75.css integrity="sha256-GQlRJzV+1tKf4KY6awAMkTqJ9/GWO3Zd03Fel8mFLnU="></noscript><script src=/lib/autocomplete/autocomplete.min.ae2da1bd62c6469ee27770ad1cddf2e8296d8a7f6d85b091463e5200c5e320af.js integrity="sha256-ri2hvWLGRp7id3CtHN3y6Cltin9thbCRRj5SAMXjIK8=" defer></script><script src=/lib/lightgallery/lightgallery.min.7de2854e7954105f2b91ff5983749c4e3c7af51e05aae279f8a5d66994a85777.js integrity="sha256-feKFTnlUEF8rkf9Zg3ScTjx69R4FquJ5+KXWaZSoV3c=" defer></script><script src=/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.4fbc3ec1878e90348b71b3594d8ef27c4f10a1a4c6d5e74948d0ee59018fd87c.js integrity="sha256-T7w+wYeOkDSLcbNZTY7yfE8QoaTG1edJSNDuWQGP2Hw=" defer></script><script src=/lib/lightgallery/plugins/zoom/lg-zoom.min.821a2adb8005511c0ad9ef6f395c1b74beacc2da194cd13a4ac43d341246e085.js integrity="sha256-ghoq24AFURwK2e9vOVwbdL6swtoZTNE6SsQ9NBJG4IU=" defer></script><script src=/lib/typeit/index.umd.96b5f642c8fe44454a419adf52ef6949f8b3b6f071f6dff508773b5bbd6444c8.js integrity="sha256-lrX2Qsj+REVKQZrfUu9pSfiztvBx9t/1CHc7W71kRMg=" defer></script><script src=/lib/katex/copy-tex.min.07770af90943a1de1a1010794bc78c6a7346d46d48fb63e35cc76ba76b827604.js integrity="sha256-B3cK+QlDod4aEBB5S8eManNG1G1I+2PjXMdrp2uCdgQ=" defer></script><script src=/lib/pangu/pangu.min.8feca3e7a71d118d82c2456d1b2cf5f1f3726c51a930627c2711b7192c8edbe2.js integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" defer></script><script src=https://vercount.one/js async defer></script><script>window.config={enablePWA:!0,lightgallery:!0,pangu:{enable:!0,selector:"article"},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},siteTime:"2026-01-10T11:15:22+08:00",typeit:{cursorChar:"|",cursorSpeed:1e3,duration:-1,loop:!1,speed:100},version:"v0.4.2-20260109063229-50d27e0e"}</script><script src=/js/theme.min.dd1317e1bcab36f6f585bd3c96f7bff3cebc093a5bebc5d3d8a8c1263f0b1ddd.js integrity="sha256-3RMX4byrNvb1hb08lve/8868CTpb68XT2KjBJj8LHd0=" defer></script></body></html>